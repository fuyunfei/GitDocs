
\section{Layer Decomposition}
Digital painting with different layers is an integral feature of digital image editing software, such as Photoshop and Sketchbook. Layers offer an intuitive way to edit the color and geometry of components and localize changes to the desired portion of the final image. Without layers, brushstroke segmentation becomes extremely challenging, since they can overlap and blend with each other.
In general, each layer represents one coat of a painting with a single color that is applied with varying opacity throughout the input painting. Wrong layer decomposition may cut one stroke into different layers. It is crucial to preserve the completeness and smoothness of the brushstrokes in layer decomposition. To this end, we modify the layer decomposition algorithm in [ CITATION Tan16 \l 2057 ] by involving the coherent lines [CITATION Kan07 \l 2057 ] in our implementation. In the following we first address the layer decomposition algorithm briefly and then discuss our modification.
\subsection{Layer Decomposition Scheme}
The “A over B” compositing and blend mode in [ CITATION Por84 \l 2057 ] is described that when the pixel A with color  and translucency  is placed over the pixel B with color  and translucency , the observed color is,
\begin{equation} \label{eq:aoverb}
\left ( \frac{A}{B} \right )_{RGB}=\frac{\alpha_{A}A_{RGB}-(1-\alpha_{A})\alpha_{B}B_{RGB}}{\left ( \frac{A}{B} \right )_{\alpha}} 
\end{equation} 
where 
\[\left ( \frac{A}{B} \right )_{\alpha} = \alpha_{A}+(1-\alpha_{A})\alpha_{B} \]
Each pixel’s color is viewed as the convex combination of all layers’ colors. For each pixel, the observed color $p$ can be approximated by the recursive application of the compositing and blend model. We take as input ordered RGB layer colors through computing per-pixel opacity values for each layer. The following ‘polynomial’ regularization term penalizes the difference between the observed color $p$ and the polynomial approximation,
\[E_{polynomial}=\frac{1}{K}\left \|    C_{n}+\sum_{i=1}^{n}  \left ( \left ( C_{i-1}-C_{i} \right ) \prod_{j=i}^{n}(1-\alpha_{j}) \right )-p  \right \|^{2}\]
where $ C_{i} $ denotes the $i$-th layer’s color, $ \alpha_{i} $ is the opacity of $ C_{i} $ , the background color  $ C_{0} $  is opaque, and  or 4 depending on the number of channels (RGB or RGB-α). The opacity penalty is expressed as,
\[E_{opaque}=\frac{1}{n}\sum_{i=1}^n-(1-\alpha_{i})^2\]
The default smoothness penalty is expressed as,
\[E_{spatial}=\frac{1}{n}\sum_{i=1}^n( \bigtriangledown  \alpha_{i})^2\]
where  is the spatial gradient of opacity in the i-th layer. This term penalizes solutions which are not spatially smooth. However, the gradient of opacity is not always aligned with that of intensity, which may result in edges discontinuous.\\
The users may specify the layer order in advance, as well as the number of layers, n, is given. The opacity for every layer may be solved by minimizing the following combined cost function,
\begin{equation}
E=\omega_{polynomial}E_{polynomial}+\omega_{opaque}E_{opaque}+\omega_{spatial}E_{spatial}
\label{eq:layer1}
\end{equation} 
where $\omega_{polynomial} = 375 ,\omega_{opaque}=1 , \omega_{spatial}=10$.
\subsection{Modified Layer Decomposition}
To enhance the smoothness and completeness of edges, the coherent line drawing technique in [CITATION Kan07 \l 2057 ] is introduced to Eq.(1), which is a ﬂow-guided anisotropic ﬁltering framework. Figure 2 shows the edge tangent flow (ETF) field of a Rosemaling painting. First, we involve the ETF field into . The ETF field is defined as,
\begin{equation}
t^{new(x)}=\frac{1}{k}\sum_{y\in\Omega(x)} \varphi(x,y)t^{current}(y)\omega_{s}(x,y)\omega_{m}(x,y)\omega_{d}(x,y)
\label{eq:layer_etf} 
\end{equation}
where $t(x)$ denotes the normalized tangent vector at pixel $x$, $\Omega(x)$ denotes the neighborhood of the pixel $x$, and $k$ is the term of vector normalization. The spatial weight function $\omega_{s}$ employs the radially-symmetric box filter with some radius. The magnitude weight function $\omega_{m}$ is monotonically increasing, indicating that the bigger weights are given to the neighboring pixels y whose gradient magnitudes are higher than that of the central pixel $x$. This ensures the preservation of the dominant edge directions. The direction weight function,$\omega_{d}$, may enhance alignment of vectors, e.g. , while suppressing swirling flows. In addition, the sign function  is employed to prevent the swirling artefact as well.\\
Involving ETF filed of Eq.\ref{eq:layer1} in $ E_{spatial} $, the smoothness penalty is rewritten as,
\begin{equation} 
E_{flow}=\frac{1}{n} \sum_{i=1}^{n} \left \| t^{new} \right \| \left ( \bigtriangledown_{\theta}\alpha_{i} \right )^2 
\end{equation} 
where $\theta$ denotes the direction of $t^{new}$, and $ \bigtriangledown_{\theta}\alpha_{i} $ is the gradient of opacity in the direction of $t^{new}$. Moreover, we weight this penalty by the norm of $t^{new}$. Applying the updated $E_{flow}$ to the layer decomposition of Eq.\ref{eq:layer1} instead of $E_{spatial}$, the brush strokes become complete and smooth, which can be noted in Figure \ref{com eflow}.\\
Second, the coherent lines as the constraint of brushstroke edges are involved in layer decomposition of Eq.1. Herein, the coherent lines can be computed as follows.
Given a ETF field $t(x)$, the flow-guided anisotropic Difference of Gaussian (DoG) filter is employed, in which the kernel shape is defined by the local flow encoded in ETF field. Note that $t(x)$ represents the local edge direction. It is most likely to make the highest contrast in the perpendicular direction, that is, the gradient direction. When moving along the edge flow, the DoG filter is applied in the gradient direction. As a result, we can ‘exaggerate’ the filter output along genuine edges, while ‘attenuating’ the output from spurious edges. This not only enhances the coherence of the edges, but also suppresses noises. Iteratively applying this flow-based DoG filter results in a binary output which reaches a satisfactory level of line connectivity and illustration quality. The coherent lines can be regarded as the edges of brushstrokes. \\
To preserve the brush stroke edges, we assume that the opacity along the coherent lines is consistent, i.e. $min \int_{l}\Arrowvert \bigtriangledown\alpha \Arrowvert^2 dx $, where $l$ denotes the pixel collection of coherent lines. Hence, the constraint term is defined by applying Laplacian operator to the opacity along the coherent lines,

\begin{equation} 
E_{edge}=\Arrowvert LY \Arrowvert^2 
\end{equation} 

where all the opacity $\alpha_i$ are stacked in the vector $Y$, and $L$ denotes the Laplacian connection matrix. The eight-connected neighboring rule is utilized to construct the connection matrix $L$, that is, if two adjacent pixels, i and j, stay on the same coherent line, the item of $L(i,j)$ is set to -1 ; otherwise 0. Figure \ref{com:edge} shows that the brush strokes become visible and complete after involving $E_{edge}$ into Eq.\ref{eq:layer1}.
Accordingly, the layer decomposition of Eq.\ref{eq:layer1} is rewritten as,

\begin{equation}
E=\omega_{polynomial}E_{polynomial}+
\omega_{opaque}E_{opaque}+\omega_{flow}E_{flow}+\omega_{edge}E_{edge}
\label{eq:layer_sum}
\end{equation} 

where $\omega_{flow} = 10 ,\omega_{edge}=1$ for all our examples. For comparison, we perform the schemes of Eq.1 and Eq.5 separately on the same set of brush paintings and compare the root-mean-square-error (RMSE) of the opacity of the coherent lines on each layer shown in Table 1. The RMSE by Eq.5 is noticeably less than that by Eq.1. This means that the coherent lines have been embedded into the opacity of each layer. The weights are empirically determined in terms of the opacity RMSE of coherent lines. Moreover, the resulting opacity of every layer by Eq.5 is shown in the left column of Figure 4.
\subsection{Iterative Scheme}
For the given layer’s colors, the current layer decomposition methods may segment the input image into the different layers in terms of the nonzero opacity or thresholding opacity. However, it can be noted in Figure 4 that there are a few of regions to be shared with multiple layers since such regions have nonzero opacities (or more than thresholds) at the multiple layers. This implies that the more layers are required. As there is a lack of layers, the colors of such regions have to be yielded by blending the colors of multiple layers.\\
Moreover, it can be noted that such regions may be categorized into two kinds, one is the region overlapped by multiple brushstrokes, and the other is the isolated one, as shown in Figure 5. The former is always merged into the other regions within some layers, while the latter is always isolated in all layers. It is natural to view the isolated regions as potential strokes. We therefore set the average of colors of some isolated region as the new layer’s color, and then re-compute the opacity of each layer by solving Eq.5. Figure 4 shows the comparison of before and after adding a new layer. The histograms indicate that the first 3 layers have no distinct changes and the new layer brings about slight influence to the previous classification results.\\
Furthermore, to remove the isolated regions, it can be achieved by adding the new layers in an iterative way. Usually, after 1 or 2 iterations, there is no isolated region in the new layer. This can be noted in Figure 5, that is, after 1 iteration, the overlapped regions have a slight change, while the isolated regions have a distinct change.
\subsection{Brushstroke Completion}
Figure 4 shows the overlapped regions in multiple layers, which bring about the gaps to break the brushstrokes within a layer. Obviously, to make brushstrokes complete and smooth, these gaps need to be filled. It is natural to involve users’ interventions, such as masks or sketches by manual, which specify the gaps to be filled.\\
Once the overlapped regions are determined, we employ the patch-based inpainting techniques [] here, that is, within one layer, the gap is specified by a mask, while the patches are extracted from the outside of the gap in all layers and are utilized to create the patch dictionary. Then, the gap is filled through iteratively projecting each patch of the layer to its nearest neighbor in the dictionary. Figure 6 shows that such patch-based inpainting methods can effectively deal with the scenario of big gap.
