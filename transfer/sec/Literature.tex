\chapter{LITERATURE REVIEW}
This chapter reviews notable bas-relief generation methods classified into two categories, methods based on 3D model and method based on 2D image, which are reviewed in section \ref{ref3D} and section \ref{ref2dimage} respectively. The structure of these bas-relief generation methods is shown in Figure \ref{liter-review-stru}. Following with section \ref{sectionbss} which reviews notable brush stroke extraction methods and some relative works.
\begin{figure}[H]
	\centering
	\includegraphics[width=15cm]{liter-review.jpg}
	\caption{Bas-relief generation from brush strokes}
	\label{liter-review-stru}
\end{figure}

\section{Bas-relief Generation from 3D Model}\label{ref3D}
A significant amount of methods has been considered bas-relief generation from 3D model,\cite{cignoni1997computer} firstly proposed a method which  creates bas-relief models by linearly compressing (squeezing) the
depth map of 3D models. This method fails to handle the depth gap between in 3D models and the output bas-reliefs can not successfully preserve the  details on 3D models. 
Some researchers considered bas-relief generation as a geometry counterpart of the  high dynamic range (HDR) image compression problem widely studied in computer graphics\cite{song2007automatic}. This approach calculates the differential coordinates of the input 3D models, then HDR image process method is applied to compress the 3D models. The output bas-relief can preserve salient feature and de-emphasize the others,but sometimes the bas-relief can be distorted and exaggerated. 
The methods proposed in \cite{kerber2009feature}\cite{kerber2012computer} work on the gradient domain of depth map of 3D models, and rely on the combination of a saliency measure and a feature enhancement technique. These methods produce generally satisfactory bas-relief output,and preserve the features of 3D models, although again some areas can be over-emphasized. 
\cite{sun2009bas} generate the bas-relief with a optimized contrast-limited adaptive histogram equalization (CLAHE) method,in which the depth map of 3D model is compressed . Local contrast of depth map can be enhanced in this method,however, the detail preservation requires high resolution depth map from 3D model. \\ \\ 
These 3D model based methods can often generate bas-relief with acceptable quality , but they all require inputs in the form of 3D models, which are often difficult and time-consuming to prepare, and obviously unsuited for bas-relief generation from 2D paintings. 

\section{Bas-relief Generation from 2D Image}\label{ref2dimage}
Automatic bas-relief generation from 2D image has recently become a significant research topic. Researches have explored recovering depth information from images specifically for the purpose of generating bas-reliefs.\newline
\subsection{Photograph Based Methods}
Some methods generation bas-relief from a photograph \cite{zeng2014region}\cite{wu2013making} \cite{alexa2010reliefs}\cite{wu2008interactive}. And the very importance part of these methods is generating bas-relief surface based on shape from shading(SFS) algorithm. SFS is a relative classic way for 3D shape recovery; see Zhang's survey \cite{zhang1999shape}.  The computation process normally involved with several concepts : depth $Z(x,y)$, surface normal $n_x,n_y,n_z$ ,and surface gradient $p,q$. The depth can either be considered as distance from viewpoint to query surface or the height from surface to default $x-y$ plane. The normal is perpendicular to the surface gradient, namely $\left( n_x,n_y,n_z\right) * \left( p, q ,1\right)^T =0  $ , the surface gradient is the changing rate of depth in $x$ and $y$ direction.

Shape from shading (SFS) is able to recover the shape of an object from a given single image, assuming illumination and reflectance are known (or assuming reflectance is uniform across the entire image). Many methods have been developed, which may be categorized into four PDEs models\cite{prados2003perspective}, (1) orthographic SFS with a far light source \cite{lions1993shape}; (2) perspective SFS with a far light source\cite{prados2004unifying}; (3) perspective SFS with a point light source at the optical center\cite{prados2003perspective}; (4) a generic Hamiltonian. However, SFS is an ill-posed problem. The notable difficulty in SFS is the bas-relief ambiguity\cite{belhumeur1999bas}, that is, the absolute orientation and scaling of a surface are ambiguous given only shading information. To amend it, many SFS algorithms impose priors on shape, depth cues produced by a stereo system, or assume that the light source, the surface reflectance, and the camera are known\cite{zhang1999shape} \cite{alldrin2007resolving} \cite{johnson2011shape} \cite{barron2012color}.\\ \\
Unfortunately,these photograph based methods assume  illumination and reflectance are known, and the image is formed from lighting and shading, which may work well for realistic photographs rather than paintings,especially for Chinese painting. Simply applying SFS method is not enough to generate bas-relief with acceptable quality .  

\subsection{Line Drawing Based Methods}
Line drawing is a drawing made exclusively in solid lines. Rather than generating bas-relief from a photograph from real scene,some researches focus on bas-relief generation methods from line drawing.
Kolomenkin et al.\cite{kolomenkin2011reconstruction}  aims to reconstruct a model from a complex line drawing that consists of many inter-related lines. At first, they extract the curves from line drawing. Then, junctions between lines are detected and margins are generated. By analyzing the connectivity between boundaries and curves, they reduce the problem to a constrained topological ordering of a graph. From these boundaries and curves with given depth, they use smooth interpolation across regions generate the bas-relief surface. Similarly, line labeling methods has been applied for shape construction from line drawings  \cite{varley2002estimating}\cite{malik1987interpreting}\cite{sykora2014ink}. A labeling process would classify segmented lines into different labels, such as concave, convex and occluding, and these labels can give clues for the shape generation of bas-relief. 
\cite{sykora2014ink} proposed a bas-relief generation method consists of six main steps: segmentation, completion, layering, inflation, stitching, and grafting.This method combines user indications and shape inflation to model smooth bas-relief shapes from line drawings. \\ \\ 
However,line drawing based methods do not consider how to generate bas-reliefs with surface details: their approaches are limited to using information contained in a line drawing, which are not suited for brush strokes which contain information such as color,texture and stroke shape. 

\subsection{Gradient and Intensity Based Methods}
Wang et al.\cite{wang2010image} demonstrate a method by constructing bas-reliefs from 2D images based on gradient operations. In their research image gradients were calculated, then by smoothing gradients to smooth shape changes. Finally , they boost fine features with user input masks.
The height image was constructed modified height map. The pixel heights are compressed, and a triangle mesh representing the bas-relief is determined by placing a vertex at each pixel position. Most features can be preserve by proposed method, but no consideration is made for the front-to-back or overlapping relationship between different image regions. \newline
\cite{li2012restoration} present a two-level approach for height map estimation from the rubbing images of restoring brick and stone relief.  The relief is separated into low and high frequency components. The base relief of the low frequency component is estimated automatically with a partial differential equation (PDE)-based mesh deformation scheme. The high frequency detail is estimated directly from rubbing images automatically or optionally with minimal interactive processing. This method works well for reliefs based on stone rubbing images, but is unsuited to general photographs or paintings.

\section{Brush Stroke Extraction}\label{sectionbss}

To the best of our knowledge, there is lack of study on extracting brush strokes from paintings. We give a brief overview of the work related to the relevant topics, i.e. decomposing images into layers and stroke extraction, which are employed in our implementation. In digital image editing, layers organize images. However, scanned paintings and photographs have no such layers. Without layers, simple edits may become very challenging.\\
Richardt et al.\cite{richardt2014vectorising} present an approach to produce editable vector graphics, in which the selected region is decomposed into a linear or radial gradient and the residual, background pixels . \cite{mccann2009local},\cite{mccann2012soft}present two generalized layer decomposition methods, which allow pixels to have independent layer orders and layers to partially overlap each other.\cite{tan2016decomposing} present a layer decomposition method based on RGB-space geometry. They assume that all possible image colors are convex combinations of the paint colors. Computing the convex hull of image colors and per-pixel layer opacities is converted into a convex optimization problem. Thus, method in \cite{tan2016decomposing} can work well without prior knowledge of paint colors. However the proposed method simply focus on layer decomposition not stroke extraction, how to extract the brush stroke remains a problem.\\ 
Li et al.\cite{li2012rhythmic} describe a method based on seed growing for brush stroke segmentation.Starting from seed coordinates, neighboring pixels are visited by exploiting a region-growing-based approach with a variable threshold, which is initialized at a predefined and automatic updated by a shape validation method. In this research,they generated manually marked brush strokes using 10 example regions from van Gogh's paintings, and they define two parameters in order to evaluate the accuracy of extracted brush stroke. In section \ref{comparevan}, we compared our method with this method.  \\
Xu et al.\cite{xu2006animating} aims at decomposing Chinese paintings into a collection of layered brush strokes, with an assumption that at most two strokes are overlapping. However, their approach requires a good amount of prior knowledge of shape and order of strokes.And it requires professional artists to build a brush stroke library which makes it a challenging and time consuming process. While our method needs no brush stroke library, and our segmentation is based on multiple layers which more than two brush strokes could overlap each others(Figure \ref{mser:alpha}). \\ \\
Most Stable Extremal Regions (MSERs) algorithm\cite{matas2004robust} has been proved to be a very efficient way in stroke segmentation from scene text images\cite{neumann2011text}\cite{gomez2013multi}, 
and the revised version has been widely used in stroke segmentation of handwritten characters\cite{gomez2016fast}.\\
The Most Stable Extremal Regions (MSERs) algorithm\cite{matas2004robust} was used for establishing correspondence in wide-baseline stereo.\cite{donoser2006efficient} introduced the data structure of the component tree in it and further developed it as an efficient segmentation approach, which prunes the component tree and selects only the regions with a stable shape within a range of level sets.\\
However, it is likely that MSERs may fail in segmentation with the following scenarios,\newline (1) two adjacent regions with the similar intensity; \newline (2) the region with a high transparency. \newline
(3) Moreover, like the other existing segmentation approaches, the MSERs algorithm encounters over-segmentation issue as well. \\
To tackle these challenges, the coherent lines method \cite{kang2007coherent} is introduced into MSERs in our algorithm, which both enhances the edges of strokes and preserves the completeness of strokes, see Section \ref{modimesr}. 

\newpage