\chapter{LITERATURE REVIEW}

\section{Bas-relief Generation from 3D model}
A significant amount of methods has been considered bas-relief generation from 3D models,\cite{cignoni1997computer} firstly proposed a method which  creates bas-relief models by linearly compressing (squeezing) the
depth map of 3D models. This method can not handle the depth gap between in 3D models and the output bas-reliefs can not successfully preserve the  details on 3D models. 
Some researchers considered bas-relief generation as a geometry counterpart of the  high dynamic range (HDR) image compression problem widely studied in computer graphics\cite{song2007automatic}. This approach calculates the differential coordinates of the input 3D models, then HDR image process method is applied to compress the 3D models. The output bas-relief can preserve salient feature and de-emphasize the others,but sometimes the bas-relief can be distorted and exaggerated. 
The methods proposed in \cite{kerber2009feature}\cite{kerber2012computer} work on the gradient domain of depth map of 3D models, and rely on the combination of a saliency measure and a feature enhancement technique. these methods produce generally satisfactory bas-relief output,and preserve the features of 3D models, although again some areas can be over-emphasized. 
\cite{sun2009bas} generate the bas-relief with a optimized contrast-limited adaptive histogram equalization (CLAHE) method,in which the depth map of 3D model is compressed . Local contrast of depth map can be enhanced in this method,however, the detail preservation requires high resolution depth map from 3D model. \\ \\ 
These 3D model based methods can often generate bas-relief with acceptable quality , but they all require inputs in the form of 3D models, which are often difficult and time-consuming to prepare. Even with 3D scanners to automatic capture the 3D shape of objects, it is still nearly impossible capture the 3D scene from a 2D painting. 

\section{Bas-relief Generation from 2D image}
Automatic bas-relief generation from 2D image has recently become a significant research topic. Researches have explored recovering depth information from images specifically for the purpose of generating bas-reliefs.\newline
\subsection{Shape from shading(SFS) based methods}
Some work uses Shape from shading for generating  bas-relief from 2D images. SFS is a relative classic way for 3D shape recovery; see Zhang's survey \cite{zhang1999shape}.  The computation process normally involved with several concepts : depth $Z(x,y)$, surface normal $n_x,n_y,n_z$ ,and surface gradient $p,q$. The depth can either be considered as distance from viewpoint to query surface or the height from surface to default $x-y$ plane. The normal is perpendicular to the surface gradient, namely $\left( n_x,n_y,n_z\right) * \left( p, q ,1\right)^T =0  $ , the surface gradient is the changing rate of depth in $x$ and $y$ direction.

Shape from shading (SFS) is able to recover the shape of an object from a given single image, assuming illumination and reflectance are known (or assuming reflectance is uniform across the entire image). Many methods have been developed, which may be categorized into four PDEs models\cite{prados2003perspective}, (1) orthographic SFS with a far light source \cite{lions1993shape}; (2) perspective SFS with a far light source\cite{prados2004unifying}; (3) perspective SFS with a point light source at the optical center\cite{prados2003perspective}; (4) a generic Hamiltonian. However, SFS is an ill-posed problem. The notable difficulty in SFS is the bas-relief ambiguity\cite{belhumeur1999bas}, that is, the absolute orientation and scaling of a surface are ambiguous given only shading information. To amend it, many SFS algorithms impose priors on shape, depth cues produced by a stereo system, or assume that the light source, the surface reflectance, and the camera are known\cite{zhang1999shape} \cite{alldrin2007resolving} \cite{johnson2011shape} \cite{barron2012color}.\\ \\
Unfortunately, SFS based methods is assuming illumination and reflectance are known, and the image is formed from lighting and shading, which works well for realistic photographs rather than paintings. 

\subsection{Line drawing based methods}
Line drawing is drawing made in solid lines. Rather than generating bas-relief from a photograph,some researches focus on bas-relief generation methods from 2D image of line drawing.
Kolomenkin et al.\cite{kolomenkin2011reconstruction}  aims to reconstruct a model from a complex line drawing that consists of many inter-related lines.At first, they extract the curves from line drawing.Then,junctions between lines are detected and margins are generated. By analyzing the connectivity between boundaries and curves, they reduce the problem to a constrained topological ordering of a graph. From these boundaries and curves with given depth, they use smooth interpolation across regions generate the bas-relief surface. Similarly,line labeling methods has been applied for shape construction from line drawings  \cite{varley2002estimating}\cite{malik1987interpreting}\cite{sykora2014ink}. A labeling process would classify segmented lines into different labels, such as concave, convex and occluding, and these labels can give clues for the shape generation of bas-relief. 
\cite{sykora2014ink} proposed a bas-relief generation method consists of six main steps: segmentation, completion, layering, inflation, stitching, and grafting.This method combines user indications and shape inflation to model smooth bas-relief shapes from line drawings. \\ \\ 
However,line drawing based methods do not consider how to generate bas-reliefs with surface details: their approaches are limited to using information contained in a line drawing, which are not suited for brush strokes which contain information such as color,texture and stroke shape. 

\subsection{Gradient and intensity based methods}
Wang et al.\cite{wang2010image} demonstrate a method by constructing bas-reliefs from 2D images based on gradient operations. In their research image gradients was first calculated, then by smoothing gradients to smooth shape changes. Finally , they boost fine features by masks.
The height image was constructed modified height map. The pixel heights are compressed, and a triangle mesh representing the bas-relief is determined by placing a vertex at each pixel position. By proposed  algorithm most features can be preserve , but no consideration is made for the overlapping relationship between different image regions, which is not suitable for brush paintings. \newline
\cite{li2012restoration} present a two-level approach for height map estimation from the rubbing images of restoring brick and stone relief.  The relief is separated into low and high frequency components. The base relief of the low frequency component is estimated automatically with a partial differential equation (PDE)-based mesh deformation scheme. The high frequency detail is estimated directly from rubbing images automatically or optionally with minimal interactive processing. This method works well for reliefs based on stone rubbing images, but is unsuited to general photographs or paintings.

\section{Stroke Segmentation}

To the best of our knowledge, there is lack of study on extracting brush strokes from paintings. We give a brief overview of the work related to the relevant topics, i.e. decomposing images into layers and stroke segmentation, which are employed in our implementation. In digital image editing, layers organize images. However, scanned paintings and photographs have no such layers. Without layers, simple edits may become very challenging.

Richardt et al.\cite{richardt2014vectorising} present an approach to produce editable vector graphics, in which the selected region is decomposed into a linear or radial gradient and the residual, background pixels . \cite{mccann2009local},\cite{mccann2012soft}present two generalized layer decomposition methods, which allow pixels to have independent layer orders and layers to partially overlap each other.\cite{tan2016decomposing} present a layer decomposition method based on RGB-space geometry. They assume that all possible image colors are convex combinations of the paint colors. Computing the convex hull of image colors and per-pixel layer opacities is converted into a convex optimization problem. Thus, their method can work well without prior knowledge of shape and overlap of strokes.

Li et al.\cite{li2012rhythmic} describe a method based on seed growing for brush stroke segmentation.Starting from seed coordinates, neighboring pixels are visited by exploiting a region-growing-based approach with a variable threshold, which is initialized at a predefined and automatic updated by a shape validation method. But their brush stroke segmentation is limited to finding brush strokes in Van Gogh's paintings, and it does not support segmenting overlapped strokes.

Xu et al.\cite{xu2006animating} aims at decomposing Chinese paintings into a collection of layered brush strokes, with an assumption that at most two strokes are overlapping. And their approach requires a good amount of prior knowledge of shape and order of strokes.The segmentation of brush strokes is based on using a brush stroke library. While our method needs no brush stroke library, and our segmentation is based on multiple layers which more than two brush strokes could overlap each others(Figure \ref{mser:alpha}). 

Most Stable Extremal Regions (MSERs) algorithm\cite{matas2004robust} has been proved to be a very efficient way in stroke segmentation from scene text images\cite{neumann2011text}\cite{gomez2013multi}, 
and the revised version has been widely used in stroke segmentation of handwritten characters\cite{gomez2016fast}.

The Most Stable Extremal Regions (MSERs) algorithm\cite{matas2004robust} was used for establishing correspondence in wide-baseline stereo.\cite{donoser2006efficient} introduced the data structure of the component tree in it and further developed it as an efficient segmentation approach, which prunes the component tree and selects only the regions with a stable shape within a range of level sets, see Section 5.1.

However, it is likely that MSERs may fail in segmentation with the following scenarios,\newline (1) two adjacent regions with the similar intensity; \newline (2) the region with a high transparency. \newline
(3) Moreover, like the other existing segmentation approaches, the MSERs algorithm encounters over-segmentation issue as well. To tackle these challenges, the coherent lines \cite{kang2007coherent} is introduced into MSERs in our algorithm, which both enhances the edges of strokes and preserves the completeness of strokes, see Section 5.2. 

\newpage